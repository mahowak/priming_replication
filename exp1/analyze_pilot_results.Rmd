---
title: "Pilot 1 Analysis Notebook"
author: "Kyle Mahowald"
date: "12/31/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(brms)
```

# Data processing

```{r}
d = read_csv("../pilot1_20201230/coded_results_exp1.csv") %>%
  mutate(num_words_completion = sapply(strsplit(completion, " "), length)) %>%
  group_by(subject) %>%
  mutate(pct_one_word = mean(num_words_completion == 1),
         mean_NA = mean(completion == "U")) %>%
  group_by(subject, completion) %>%
  mutate(same_num = n()) %>%
  group_by(subject) %>%
  mutate(max_n = max(same_num)) %>%
  ungroup() 
```

# Exclusions

Exclude participants with more than 50% NA, more than 50% one word, or 8+ one-word answers.

```{r}

group_by(d, subject) %>%
  summarise(first(max_n),
            first(pct_one_word),
            first(mean_NA))

d = filter(d, max_n < 8,
           pct_one_word < .50,
           mean_NA < .50) 

group_by(d, type, condition) %>%
  summarise(mean.do = mean(code == "D"),
            mean.po = mean(code == "P"),
            mean.other = mean(code != "P" & code != "D"))
```

# Analysis 

We merge primes and targets, to match them up and filter to only correct prime trials.

```{r}
primes = filter(d, type == "prime") %>%
  mutate(correct = (grepl("DO", condition) & code == "D") | (grepl("PO", condition) & code == "P")) %>%
  rename(prime.cond = condition) %>%
  select(subject, item, correct, prime.cond)

mean(primes$correct)
targets = filter(d, type == "target") %>%
  left_join(primes)
```

Look at items with high other proportions.

```{r}

group_by(d, type, condition) %>%
  summarise(mean.do = mean(code == "D"),
            mean.po = mean(code == "P"),
            mean.other = mean(code != "P" & code != "D"))


group_by(d, type, condition, item, prime, target_verb) %>%
  filter(type == "target") %>%
  summarise(mean.do = mean(code == "D"),
            mean.po = mean(code == "P"),
            mean.other = mean(code != "P" & code != "D")) %>%
  arrange(-mean.other) 

group_by(d, type, condition, target_verb) %>%
  filter(type == "target") %>%
  summarise(mean.do = mean(code == "D"),
            mean.po = mean(code == "P"),
            mean.other = mean(code != "P" & code != "D")) %>%
  arrange(-mean.other)

group_by(d, type, condition) %>%
  filter(code == "D" | code == "P") %>%
  summarise(mean.do = mean(code == "D"),
            mean.po = mean(code == "P"),
            mean.other = mean(code != "P" & code != "D"))

```

Filter to a data frame with just target attachments and with onbly correct primes.

```{r}

d.analyze = filter(targets, correct == T,
                   code == "D" | code == "P")

select(d.analyze, item, prime, completion, code, prime.cond)
```


## Priors and contrast codes

Do contrast coding, set priors that include more and less informative priors, as well as prior for null model.

```{r}

d.analyze = mutate(d.analyze,
                   respcode = ifelse(code == "D", 1, 0),
                   boost = case_when(grepl("same", prime.cond) ~ .5,
                                     TRUE ~ -.5),
                   prime.boost = case_when(prime.cond == "DO-same" ~ .5,
                                           prime.cond == "PO-same" ~ -.5,
                                           TRUE ~ 0),
                   prime.noboost = case_when(prime.cond == "DO-diff" ~ .5,
                                             prime.cond == "PO-diff" ~ -.5,
                                             TRUE ~ 0))

priors <-c(set_prior("normal(0, .5)", class = "Intercept"),
           set_prior("normal(0, .5)", class = "b"),
           set_prior("normal(0, .05)", class = "sd"),
           set_prior("lkj(2)", class = "L"),
           set_prior("normal(0, .5)", class = "sd", group="subject", coef="Intercept" ),
           set_prior("normal(0, .5)", class = "sd", group="item", coef="Intercept" ))

less.informative.priors <-c(set_prior("normal(0, 2)", class = "Intercept"),
                                   set_prior("normal(0, 2)", class = "b"),
                                   set_prior("normal(0, 2)", class = "sd"),
                                   set_prior("lkj(2)", class = "L"),
                                   set_prior("normal(0, 2)", class = "sd", group="subj", coef="Intercept" ),
                                   set_prior("normal(0, 2)", class = "sd", group="item", coef="Intercept" ))

```

## Make graphs

Make a plot by condition, with error bars over subjects.


```{r}
mutate(d.analyze, `prime condition` = ifelse(grepl("DO", prime.cond), "DO", "PO"),
         `same verb` = ifelse(grepl("same", prime.cond), "same", "different")) %>%
  group_by(subject, `prime condition`, `same verb`) %>%
  summarise(m=mean(respcode)) %>%
  group_by(`prime condition`, `same verb`) %>%
  summarise(mean.prime = mean(m),
            se.prime = sd(m)/sqrt(n())) %>%
  ggplot(data=., aes(x=`prime condition`, y=mean.prime,
                     ymin = mean.prime - 1.96 * se.prime,
                     ymax = mean.prime + 1.96 * se.prime,
                     group=`same verb`,
                     colour = `same verb`)) +
  geom_errorbar(width=.3, position=position_dodge(width=.5)) +
  geom_point(position=position_dodge(width=.5)) + 
  theme_bw(18) + 
  ylab("mean choosing DO") + 
  ylim(-.1, 1)
```


## Fit models

Fit models and compute BF. For the final version, run with more chains and a higher number of iterations to ensure convergence. We will run 16 chains, each for 60k iterations. If there are errors, we will address those until the model runs with no errors.

```{r, results="hide"}

full.model = brm(respcode ~ boost + prime.boost + prime.noboost + 
                   (boost + prime.boost + prime.noboost | subject) + 
                   (boost + prime.boost + prime.noboost | item),
                 prior = priors,
                 data = d.analyze, 
                 family = 'bernoulli',
                 chains=4, cores=4,
                 save_all_pars = T,
                 iter=30000)

# probability boost prime is bigger than no boost prime
mean(fixef(full.model, summary = F)[, "prime.boost"] > 
          fixef(full.model, summary = F)[, "prime.noboost"])

null.model.1 = brm(respcode ~ boost + prime.boost  + 
                     (boost + prime.boost + prime.noboost | subject) + 
                     (boost + prime.boost + prime.noboost | item),
                   prior = priors,
                   data = d.analyze, 
                   family = 'bernoulli',
                   chains=4, cores=4,
                   save_all_pars = T,
                   iter=30000)

null.model.2 = brm(respcode ~ boost + prime.boost + prime.noboost + 
                     (boost + prime.boost + prime.noboost | subject) + 
                     (boost + prime.boost + prime.noboost | item),
                   prior = priors,
                   data = d.analyze, 
                   family = 'bernoulli',
                   chains=4, cores=4,
                   save_all_pars = T,
                   iter=30000)


bf1 = bayes_factor(full.model, null.model.1)
bf2 = bayes_factor(full.model, null.model.2)

print(bf1)
print(bf2)

print(full.model)
```